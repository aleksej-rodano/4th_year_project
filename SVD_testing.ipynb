{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "from ncon import ncon  # import ncon function for tensor contraction\n",
    "\n",
    "# random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax:\n",
    "U, s, Vh = scipy.linalg.svd(A, full_matrices=True, compute_uv=True)\n",
    "\n",
    "- A: The input matrix (as a NumPy array) to be decomposed.\n",
    "\n",
    "- full_matrices (optional, boolean): If True (default), U and Vh have shapes (M, M) and (N, N). If False, the shapes are (M, K) and (K, N), where K = min(M, N). Using full_matrices=False is more memory-efficient and is often called \"thin SVD\".\n",
    "\n",
    "- compute_uv (optional, boolean): If True (default), the full U and Vh matrices are computed. If False, only the singular values s are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "U (Left Singular Vectors):\n",
      "[[-0.2298477   0.88346102  0.40824829]\n",
      " [-0.52474482  0.24078249 -0.81649658]\n",
      " [-0.81964194 -0.40189603  0.40824829]]\n",
      "\n",
      "s (Singular Values as a 1D array):\n",
      "[9.52551809 0.51430058]\n",
      "\n",
      "Vh (Transposed Right Singular Vectors):\n",
      "[[-0.61962948 -0.78489445]\n",
      " [-0.78489445  0.61962948]]\n"
     ]
    }
   ],
   "source": [
    "# Create a 3x2 matrix\n",
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Decompose the matrix A\n",
    "U, s, Vh = svd(A)\n",
    "\n",
    "print(\"\\nU (Left Singular Vectors):\")\n",
    "print(U)\n",
    "\n",
    "print(\"\\ns (Singular Values as a 1D array):\")\n",
    "print(s)\n",
    "\n",
    "print(\"\\nVh (Transposed Right Singular Vectors):\")\n",
    "print(Vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: singular values are returned as 1D array and not matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction of original Matrix\n",
    "1. Create zero matrix\n",
    "2. fill diagonal with singular values\n",
    "3. perform matrix multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Sigma matrix: \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "Recostructed A \n",
      " [[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "\n",
      "Verification successful: Reconstructed matrix is close to the original.\n"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "Sigma = np.zeros(A.shape)\n",
    "print(\"Empty Sigma matrix:\", \"\\n\", Sigma)\n",
    "\n",
    "# step 2, can't use Sigma = np.diag(s), as Sigma is not a square matrix\n",
    "Sigma[: A.shape[1], : A.shape[1]] = np.diag(s)\n",
    "\n",
    "# step 3, @ operator is used for matrix multiplication\n",
    "A_recon = U @ Sigma @ Vh\n",
    "print(\"Recostructed A\", \"\\n\", A_recon)\n",
    "\n",
    "assert np.allclose(A, A_recon)\n",
    "print(\"\\nVerification successful: Reconstructed matrix is close to the original.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated SVD for Approximation\n",
    " key application of SVD is approximating a matrix by using only the top k singular values. This is the basis for techniques like Principal Component Analysis (PCA) and data compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix Approximated with k=1 singular value(s):\n",
      "[[1.35662819 1.71846235]\n",
      " [3.09719707 3.92326845]\n",
      " [4.83776596 6.12807454]]\n"
     ]
    }
   ],
   "source": [
    "# Number of components to keep\n",
    "k = 1\n",
    "\n",
    "# Truncate the matrices\n",
    "U_trunc = U[:, :k]\n",
    "Sigma_trunc = np.diag(s[:k])\n",
    "Vh_trunc = Vh[:k, :]\n",
    "\n",
    "# Reconstruct the approximated matrix\n",
    "A_approx = U_trunc @ Sigma_trunc @ Vh_trunc\n",
    "\n",
    "print(f\"\\nMatrix Approximated with k={k} singular value(s):\")\n",
    "print(A_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning any state into MPOs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psi normalised and reshaped into 2x2x2 tensor: \n",
      " [0.37454012 0.95071431 0.73199394 0.59865848 0.15601864 0.15599452\n",
      " 0.05808361 0.86617615] \n",
      " Norm: 1.6554926857708652 \n",
      "\n",
      "Reshape tensor as matrix : \n",
      "  [[0.37454012 0.95071431 0.73199394 0.59865848]\n",
      " [0.15601864 0.15599452 0.05808361 0.86617615]]\n"
     ]
    }
   ],
   "source": [
    "n = 3  # three sites = three legs\n",
    "\n",
    "# set up random tensor and normalise it\n",
    "psi = np.random.rand(2**3)\n",
    "# print(\"Psi before reshaping: \\n \", psi, \"\\n \")\n",
    "# psi = psi / np.linalg.norm(psi)  #  normalized state vector, this line is commented as it is useful to test that the code works for unnormalized states, and normalizes them automatically\n",
    "psi_initial = np.reshape(psi, (2, 2, 2))  # rewrite psi as rank-n tensor\n",
    "print(\n",
    "    \"Psi normalised and reshaped into 2x2x2 tensor: \\n\",\n",
    "    psi,\n",
    "    \"\\n Norm:\",\n",
    "    np.linalg.norm(psi),\n",
    "    \"\\n\",\n",
    ")\n",
    "\n",
    "#                      - SITE 1 -\n",
    "# Step 1 - reshape tensor to matrix, required for svd\n",
    "psi = np.reshape(psi_initial, (2, 2 ** (n - 1)))\n",
    "print(\"Reshape tensor as matrix : \\n \", psi)\n",
    "\n",
    "# Step 2 - SVD to split off first site\n",
    "U, Lambda, Vd = svd(psi, full_matrices=False)\n",
    "# print(\"Shape of U right after SVD: \\n\", U.shape)\n",
    "\n",
    "Us = []\n",
    "# Step 3.5 - add left dummy left virtual index\n",
    "U = np.reshape(U, (1, 2, 2))  # dummy_mu0, s1, mu1\n",
    "# print(\"Shape of U after reshape: \\n\", U.shape)\n",
    "Us.append(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psi' remainder (2, 4) [[-0.40467863 -0.91916538 -0.67978374 -0.92448079]\n",
      " [-0.02928011 -0.28866414 -0.27763808  0.50397259]]\n",
      "Psi' remainder reshaped: (4, 2) [[-0.40467863 -0.91916538]\n",
      " [-0.67978374 -0.92448079]\n",
      " [-0.02928011 -0.28866414]\n",
      " [-0.27763808  0.50397259]]\n",
      "U shape: (2, 2, 2) Lamda shape: (2,) Vd shape: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Compute the remainder state psi', diagonalise Lambda first since its a 1D array\n",
    "psi1_remainder = (\n",
    "    np.diag(Lambda) @ Vd\n",
    ")  # mu1, (s2 s3)     =>  this has shape (2,4) for a 3 qubits system\n",
    "print(\"Psi' remainder\", psi1_remainder.shape, psi1_remainder)\n",
    "\n",
    "#                      - SITE 2 -\n",
    "# Step 4 - Reshaping, fuse mu1 and s2, this will separate s2 and s3\n",
    "psi1_remainder = np.reshape(\n",
    "    psi1_remainder, (4, 2)\n",
    ")  # (mu1 s2), s3   =>  this has shape (4,2)\n",
    "print(\"Psi' remainder reshaped:\", psi1_remainder.shape, psi1_remainder)\n",
    "U, Lambda, Vd = svd(psi1_remainder, full_matrices=False)  # U has shape 4,2\n",
    "\n",
    "U = np.reshape(U, (2, 2, 2))  # mu1, s2, mu2\n",
    "Us.append(U)\n",
    "\n",
    "print(\"U shape:\", U.shape, \"Lamda shape:\", Lambda.shape, \"Vd shape:\", Vd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psi'' remainder reshaped: (2, 2) [[-0.69459769 -1.40818727]\n",
      " [-0.47047318  0.23206401]]\n"
     ]
    }
   ],
   "source": [
    "#                      - SITE 3 -\n",
    "# Step 5 - Compute remainder psi''\n",
    "psi2_remainder = np.diag(Lambda) @ Vd  # mu2, s3\n",
    "print(\"Psi'' remainder reshaped:\", psi2_remainder.shape, psi2_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our state vector was already normalized, the singular value in this last SVD is just 1. You could just reshape this matrix into the final tensor (mu2, s3, 1) (hence add additional virtual index) and be done.\n",
    "\n",
    "However, what if the original state was not normalized? All the \"norm\" of the state has been pushed into this final matrix. (a good exercise to confirm by skipping the normalization step in the definition of psi above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of Lambda is not 1, initial state was not normalized. Another SVD was performed to handle the norm.\n",
      "Norm of psi2_remainder: 1.6554926857708652\n",
      "Final Lambda (after SVD): [1.57017748 0.52459385]\n",
      "Is the norm of Lambda_final close to norm_psi2?  True\n",
      "Norm of U: 1.414213562373095\n",
      "(2, 2, 1) (2,) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "def norm_checker(Lamda_tmp, remainder):\n",
    "    \"Controls if the state is normalised by checking if Lamda is 1, if not it does another SVD to handle the norm\"\n",
    "    norm_lambda = np.linalg.norm(Lamda_tmp)\n",
    "    if np.allclose(norm_lambda, 1, atol=1e-8):\n",
    "        print(\"Norm of Lambda is 1, hence the state is normalized.\")\n",
    "        # add right dummy index\n",
    "        U = np.reshape(remainder, (2, 2, 1))  # Reshape to (mu2, s3, dummy_mu3)\n",
    "\n",
    "        # check that U is normalized\n",
    "        if not np.allclose(np.linalg.norm(U), 1):\n",
    "            print(\"U is not normalized, something went wrong.\")\n",
    "        Us.append(U)\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"Norm of Lambda is not 1, initial state was not normalized. Another SVD was performed to handle the norm.\"\n",
    "        )\n",
    "        # for programmatic elegance and to handle normalization, we do another SVD\n",
    "        norm_psi2 = np.linalg.norm(remainder)\n",
    "        print(\"Norm of psi2_remainder:\", norm_psi2)\n",
    "\n",
    "        # more direct method to Normalize the remainder state\n",
    "        # remainder = remainder / norm_psi2\n",
    "        # if np.allclose(np.linalg.norm(remainder), 1):\n",
    "        #     print(\"Final state is normalized after normalization step.\")\n",
    "        # else:\n",
    "        #     print(\"Final state is not normalized, something went wrong.\")\n",
    "\n",
    "        U, Lambda_final, Vd = svd(remainder, full_matrices=False)\n",
    "        # now the norm of lambda is the norm of the state\n",
    "        print(\"Final Lambda (after SVD):\", Lambda_final)\n",
    "        lambda_final_norm = np.linalg.norm(Lambda_final)\n",
    "\n",
    "        are_they_equal = np.allclose(lambda_final_norm, norm_psi2)\n",
    "        print(f\"Is the norm of Lambda_final close to norm_psi2?  {are_they_equal}\")\n",
    "        if are_they_equal:\n",
    "            print(\"Norm of U:\", np.linalg.norm(U))\n",
    "\n",
    "        # normalise remainder state\n",
    "        remainder_norm = remainder / lambda_final_norm\n",
    "\n",
    "        # Add right dummy index\n",
    "        U = np.reshape(remainder_norm, (2, 2, 1))  # Reshape to (mu2, s3, dummy_mu3)\n",
    "        Us.append(U)\n",
    "\n",
    "        print(U.shape, Lambda.shape, Vd.shape)\n",
    "\n",
    "\n",
    "norm_checker(Lambda, psi2_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compress the state by only keeping the $\\chi$\n",
    " largest singular values with their respective singular vectors. This hyper-parameter $\\chi$\n",
    " is the bond dimension. It allows us to control the amount of entanglement the state can represent between everything that is left and right of the bond "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U at site 1: (1, 2, 2)\n",
      "Shape of U at site 2: (2, 2, 2)\n",
      "Shape of U at site 3: (2, 2, 1)\n",
      "Shape of reconstructed psi from ncon: (1, 2, 2, 2, 1)\n",
      "Final shape after removing dummy indices: (2, 2, 2)\n",
      "Overlap between original and reconstructed tensor: 1.0\n",
      "\n",
      " \n",
      " Initial normalised state: \n",
      " [[[0.22624088 0.57427877]\n",
      "  [0.44216078 0.36161953]]\n",
      "\n",
      " [[0.09424303 0.09422846]\n",
      "  [0.03508539 0.52321351]]]\n",
      "\n",
      "\n",
      " Reconstructed state: \n",
      " [[[0.22624088 0.57427877]\n",
      "  [0.44216078 0.36161953]]\n",
      "\n",
      " [[0.09424303 0.09422846]\n",
      "  [0.03508539 0.52321351]]]\n"
     ]
    }
   ],
   "source": [
    "# Reconstruction of the original state from the MPS tensors\n",
    "\n",
    "# shape of Us\n",
    "for i, U in enumerate(Us):\n",
    "    print(f\"Shape of U at site {i + 1}: {U.shape}\")\n",
    "\n",
    "# 1. Define the list of tensors to contract\n",
    "tensor_list = [Us[0], Us[1], Us[2]]\n",
    "\n",
    "# 2. Define the index connections\n",
    "#    - Positive numbers are contracted. Virtual indices\n",
    "#    - Negative numbers are the open legs of the final tensor. Physical indices\n",
    "index_connections = [\n",
    "    [-1, -2, 1],  # Tensor 0: (dummy_mu0, s1, mu1)\n",
    "    [1, -3, 2],  # Tensor 1: (mu1, s2, mu2)\n",
    "    [2, -4, -5],\n",
    "]  # Tensor 2: (mu2, s3, dummy_mu3)\n",
    "\n",
    "# 3. Perform the contraction, this is an automated contraction routine\n",
    "psi_reconstruct_ncon = ncon(tensor_list, index_connections)\n",
    "\n",
    "print(f\"Shape of reconstructed psi from ncon: {psi_reconstruct_ncon.shape}\")\n",
    "\n",
    "# 4. Remove the dummy indices to get the final tensor\n",
    "# The shape is (1, 2, 2, 2, 1) corresponding to indices (-1, -2, -3, -4, -5)\n",
    "psi_final = np.reshape(psi_reconstruct_ncon, (2, 2, 2))\n",
    "\n",
    "print(f\"Final shape after removing dummy indices: {psi_final.shape}\")\n",
    "\n",
    "# 5. Verify that the reconstructed tensor matches the original tensor, compute overlap\n",
    "# first normalise the initial state\n",
    "psi_initial_norm = psi_initial / np.linalg.norm(psi_initial)\n",
    "\n",
    "# axes=([0, 1, 2] means that the inner product is taken over all three indices of the tensors\n",
    "overlap = np.tensordot(psi_initial_norm, psi_final, axes=([0, 1, 2], [0, 1, 2]))\n",
    "print(f\"Overlap between original and reconstructed tensor: {overlap}\")\n",
    "\n",
    "print(\"\\n \\n Initial normalised state: \\n\", psi_initial_norm)\n",
    "print(\"\\n\\n Reconstructed state: \\n\", psi_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An MPS is in left-canonical form if each of its tensors is a left-normalized isometry.\n",
    "This means that if you contract a tensor with its own complex conjugate over its physical and left virtual indices, you get an identity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD EQUAtion for the contraction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left-canonical check for U at site 1:\n",
      "[[ 1. -0.]\n",
      " [-0.  1.]]\n",
      "\n",
      "Left-canonical check for U at site 2:\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "Left-canonical check for U at site 3:\n",
      "[[1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if all U satisfies the left-normal isometry condition\n",
    "for i, U in enumerate(Us):\n",
    "    # Contract U_tensor with its conjugate over the left and physical indices\n",
    "    # axes=([0, 1], [0, 1]) means contract axis 0 of the first tensor with axis 0 of the second,\n",
    "    # and axis 1 of the first with axis 1 of the second.\n",
    "    # U is real, but for generality we use conjugate\n",
    "    identity_check = np.tensordot(U, np.conj(U), axes=([0, 1], [0, 1]))\n",
    "    print(f\"Left-canonical check for U at site {i + 1}:\")\n",
    "    # Use the context manager to apply formatting ONLY for this print statement\n",
    "    with np.printoptions(precision=3, suppress=True):\n",
    "        print(identity_check)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO LIST:\n",
    "- extend to 4 or more physical indixes (4 or more quibits) => make a function that does this trught a loop or something\n",
    "- Make the tests suggested By Andrew\n",
    "    - test final inner product\n",
    "    - check whether uuT* = i\n",
    "- try right- canonical form\n",
    "- Try do truncate the singular Values, and see how the reconstructed  tensor looks like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
