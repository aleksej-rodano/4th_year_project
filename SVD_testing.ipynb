{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax:\n",
    "U, s, Vh = scipy.linalg.svd(A, full_matrices=True, compute_uv=True)\n",
    "\n",
    "- A: The input matrix (as a NumPy array) to be decomposed.\n",
    "\n",
    "- full_matrices (optional, boolean): If True (default), U and Vh have shapes (M, M) and (N, N). If False, the shapes are (M, K) and (K, N), where K = min(M, N). Using full_matrices=False is more memory-efficient and is often called \"thin SVD\".\n",
    "\n",
    "- compute_uv (optional, boolean): If True (default), the full U and Vh matrices are computed. If False, only the singular values s are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "U (Left Singular Vectors):\n",
      "[[-0.2298477   0.88346102  0.40824829]\n",
      " [-0.52474482  0.24078249 -0.81649658]\n",
      " [-0.81964194 -0.40189603  0.40824829]]\n",
      "\n",
      "s (Singular Values as a 1D array):\n",
      "[9.52551809 0.51430058]\n",
      "\n",
      "Vh (Transposed Right Singular Vectors):\n",
      "[[-0.61962948 -0.78489445]\n",
      " [-0.78489445  0.61962948]]\n"
     ]
    }
   ],
   "source": [
    "# Create a 3x2 matrix\n",
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Decompose the matrix A\n",
    "U, s, Vh = svd(A)\n",
    "\n",
    "print(\"\\nU (Left Singular Vectors):\")\n",
    "print(U)\n",
    "\n",
    "print(\"\\ns (Singular Values as a 1D array):\")\n",
    "print(s)\n",
    "\n",
    "print(\"\\nVh (Transposed Right Singular Vectors):\")\n",
    "print(Vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: singular values are returned as 1D array and not matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction of original Matrix\n",
    "1. Create zero matrix\n",
    "2. fill diagonal with singular values\n",
    "3. perform matrix multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Sigma matrix: \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "Recostructed A \n",
      " [[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "\n",
      "Verification successful: Reconstructed matrix is close to the original.\n"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "Sigma = np.zeros(A.shape)\n",
    "print(\"Empty Sigma matrix:\", \"\\n\", Sigma)\n",
    "\n",
    "# step 2, can't use Sigma = np.diag(s), as Sigma is not a square matrix\n",
    "Sigma[: A.shape[1], : A.shape[1]] = np.diag(s)\n",
    "\n",
    "# step 3, @ operator is used for matrix multiplication\n",
    "A_recon = U @ Sigma @ Vh\n",
    "print(\"Recostructed A\", \"\\n\", A_recon)\n",
    "\n",
    "assert np.allclose(A, A_recon)\n",
    "print(\"\\nVerification successful: Reconstructed matrix is close to the original.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated SVD for Approximation\n",
    " key application of SVD is approximating a matrix by using only the top k singular values. This is the basis for techniques like Principal Component Analysis (PCA) and data compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix Approximated with k=1 singular value(s):\n",
      "[[1.35662819 1.71846235]\n",
      " [3.09719707 3.92326845]\n",
      " [4.83776596 6.12807454]]\n"
     ]
    }
   ],
   "source": [
    "# Number of components to keep\n",
    "k = 1\n",
    "\n",
    "# Truncate the matrices\n",
    "U_trunc = U[:, :k]\n",
    "Sigma_trunc = np.diag(s[:k])\n",
    "Vh_trunc = Vh[:k, :]\n",
    "\n",
    "# Reconstruct the approximated matrix\n",
    "A_approx = U_trunc @ Sigma_trunc @ Vh_trunc\n",
    "\n",
    "print(f\"\\nMatrix Approximated with k={k} singular value(s):\")\n",
    "print(A_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning any state into MPOs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psi normalised and reshaped into 2x2x2 tensor: \n",
      " [[[0.45218879 0.55005769]\n",
      "  [0.00554793 0.42789196]]\n",
      "\n",
      " [[0.40719939 0.37914551]\n",
      "  [0.00221827 0.0164909 ]]]\n",
      "Reshape tensor as matrix : \n",
      "  [[0.45218879 0.55005769 0.00554793 0.42789196]\n",
      " [0.40719939 0.37914551 0.00221827 0.0164909 ]]\n"
     ]
    }
   ],
   "source": [
    "n = 3 # three sites = three legs\n",
    "\n",
    "# set up random tensor and normalise it\n",
    "psi = np.random.rand(2**3)\n",
    "# print(\"Psi before reshaping: \\n \", psi, \"\\n \")\n",
    "psi = psi / np.linalg.norm(psi)  # random, normalized state vector\n",
    "psi = np.reshape(psi, (2, 2, 2)) # rewrite psi as rank-n tensor\n",
    "print(\"Psi normalised and reshaped into 2x2x2 tensor: \\n\", psi)\n",
    "\n",
    "#                      - SITE 1 -\n",
    "# Step 1 - reshape tensor to matrix, required for svd \n",
    "psi = np.reshape(psi, (2, 2**(n-1)))\n",
    "print(\"Reshape tensor as matrix : \\n \", psi)\n",
    "\n",
    "# Step 2 - SVD to split off first site\n",
    "U, Lambda, Vd = svd(psi, full_matrices=False)\n",
    "# print(\"Shape of U right after SVD: \\n\", U.shape)\n",
    "\n",
    "Us = []\n",
    "# Step 3.5 - add left dummy left virtual index\n",
    "U = np.reshape(U, (1, 2, 2)) # dummy_mu0, s1, mu1\n",
    "# print(\"Shape of U after reshape: \\n\", U.shape)\n",
    "Us.append(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psi' remainder (2, 4) [[-0.59976979 -0.66753069 -0.00587518 -0.37056813]\n",
      " [ 0.10277278  0.02678723 -0.00108746 -0.21457571]]\n",
      "Psi' remainder reshaped: (4, 2) [[-0.59976979 -0.66753069]\n",
      " [-0.00587518 -0.37056813]\n",
      " [ 0.10277278  0.02678723]\n",
      " [-0.00108746 -0.21457571]]\n",
      "U shape: (2, 2, 2) Lamda shape: (2,) Vd shape: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3 - Compute the remainder state psi', diagonalise Lambda first since its a 1D array \n",
    "psi1_remainder = np.diag(Lambda) @ Vd                 # mu1, (s2 s3)     =>  this has shape (2,4) for a 3 qubits system\n",
    "print(\"Psi' remainder\", psi1_remainder.shape, psi1_remainder)\n",
    "\n",
    "#                      - SITE 2 -\n",
    "# Step 4 - Reshaping, fuse mu1 and s2, this will separate s2 and s3\n",
    "psi1_remainder = np.reshape(psi1_remainder, (4, 2))  # (mu1 s2), s3   =>  this has shape (4,2) \n",
    "print(\"Psi' remainder reshaped:\", psi1_remainder.shape, psi1_remainder)\n",
    "U, Lambda, Vd = svd(psi1_remainder, full_matrices = False)  # U has shape 4,2\n",
    "\n",
    "U = np.reshape(U, (2, 2, 2)) # mu1, s2, mu2\n",
    "Us.append(U)\n",
    "\n",
    "print(\"U shape:\", U.shape, \"Lamda shape:\", Lambda.shape,\"Vd shape:\", Vd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psi'' remainder reshaped: (2, 2) [[ 0.56735715  0.77708658]\n",
      " [-0.22006274  0.16066957]]\n"
     ]
    }
   ],
   "source": [
    "#                      - SITE 3 -\n",
    "# Step 5 - Compute remainder psi''\n",
    "psi2_remainder = np.diag(Lambda) @ Vd                 # mu2, s3   \n",
    "print(\"Psi'' remainder reshaped:\", psi2_remainder.shape, psi2_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our state vector was already normalized, the singular value in this last SVD is just 1. You could just reshape this matrix into the final tensor (mu2, s3, 1) (hence add additional virtual index) and be done.\n",
    "\n",
    "However, what if the original state was not normalized? All the \"norm\" of the state has been pushed into this final matrix. (a good exercise to confirm by skipping the normalization step in the definition of psi above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda is not 1, initial state was not normalized. Another SVD was performed to handle the norm.\n",
      "(2, 2) (2,) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "def norm_checker(Lamda_tmp):\n",
    "    \"Controls if the state is normalised by checking if Lamda is 1, if not it does another SVD to handle the norm\"\n",
    "\n",
    "    if np.allclose(Lamda_tmp, 1):\n",
    "        print(\"Lambda is 1, hence the state is normalized.\")\n",
    "        # add right dummy index\n",
    "        U = np.reshape(psi2_remainder, (2, 2, 1)) # Reshape to (mu2, s3, dummy_mu3)\n",
    "        Us.append(U)\n",
    "    else:\n",
    "        print(\"Lambda is not 1, initial state was not normalized. Another SVD was performed to handle the norm.\")\n",
    "        # for programmatic elegance and to handle normalization, we do another SVD \n",
    "        # psi2_remainder = np.reshape(psi2_remainder, (4, 1))  # (mu1 s2), s3 \n",
    "        U, Lambda, Vd = svd(psi2_remainder, full_matrices=False)\n",
    "\n",
    "        # Add right dummy index\n",
    "        # U = np.reshape(U, (2, 2, 1)) # Reshape to (mu2, s3, dummy_mu3)\n",
    "        Us.append(U)\n",
    "\n",
    "        print(U.shape, Lambda.shape, Vd.shape)\n",
    "\n",
    "norm_checker(Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of Us: [(1, 2, 2), (2, 2, 2), (2, 2)]\n",
      "Shape of reconstructed psi: (1, 2, 2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Shapes of Us: {[_.shape for _ in Us]}\")\n",
    "\n",
    "psi_reconstruct = Us[0]\n",
    "\n",
    "for i in range(1, len(Us)):\n",
    "    # contract the rightmost with the left most index\n",
    "    psi_reconstruct = np.tensordot(psi_reconstruct, Us[i], axes=1)\n",
    "\n",
    "print(f\"Shape of reconstructed psi: {psi_reconstruct.shape}\")\n",
    "# remove dummy dimensions\n",
    "psi_reconstruct = np.reshape(psi_reconstruct, (2, 2, 2))\n",
    "# original shape of original psi\n",
    "psi = np.reshape(psi, (2, 2, 2))\n",
    "\n",
    "np.allclose(psi, psi_reconstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def contract_mpo_pair(W_left, W_right):\n",
    "#     \"\"\"\n",
    "#     Contracts two MPO tensors together.\n",
    "\n",
    "#     This function performs matrix multiplication on the bond dimensions\n",
    "#     and the Kronecker (tensor) product on the physical dimensions.\n",
    "\n",
    "#     Args:\n",
    "#         W_left: The left MPO tensor with shape (bond_l, bond_mid, phys, phys).\n",
    "#         W_right: The right MPO tensor with shape (bond_mid, bond_r, phys, phys).\n",
    "\n",
    "#     Returns:\n",
    "#         The resulting contracted tensor with shape (bond_l, bond_r, phys*phys, phys*phys).\n",
    "#     \"\"\"\n",
    "#     # Get the dimensions\n",
    "#     bond_l, bond_mid, phys, _ = W_left.shape\n",
    "#     _, bond_r, _, _ = W_right.shape\n",
    "    \n",
    "#     # The new physical dimension will be the product of the old ones\n",
    "#     new_phys_dim = phys * phys\n",
    "    \n",
    "#     # Initialize the result tensor\n",
    "#     result = np.zeros((bond_l, bond_r, new_phys_dim, new_phys_dim), dtype=complex)\n",
    "    \n",
    "#     # Sum over the shared middle bond index\n",
    "#     for i in range(bond_l):\n",
    "#         for j in range(bond_r):\n",
    "#             # Temp matrix to store the sum over the middle bond\n",
    "#             sum_matrix = np.zeros((new_phys_dim, new_phys_dim), dtype=complex)\n",
    "#             for k in range(bond_mid):\n",
    "#                 # The core operation: Kronecker product for physical indices\n",
    "#                 op_left = W_left[i, k]\n",
    "#                 op_right = W_right[k, j]\n",
    "#                 sum_matrix += np.kron(op_left, op_right)\n",
    "#             result[i, j] = sum_matrix\n",
    "            \n",
    "#     return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # --- 1. Define the Basic Operators (2x2 matrices) ---\n",
    "# I = np.identity(2, dtype=complex)\n",
    "# sz = np.array([[1, 0], [0, -1]], dtype=complex)\n",
    "# Z = np.zeros((2, 2), dtype=complex) # Zero operator for off-diagonal blocks\n",
    "\n",
    "# # --- 2. Construct the MPO Tensors ---\n",
    "# # Each tensor W has shape (bond_left, bond_right, physical, physical)\n",
    "\n",
    "# # W1: Shape (1, 3, 2, 2)\n",
    "# W1_list = [[sz, I, I]]\n",
    "# W1 = np.array(W1_list)\n",
    "\n",
    "# # W2: Shape (3, 3, 2, 2)\n",
    "# W2_list = [[sz, Z,  Z ],\n",
    "#            [Z,  sz, Z ],\n",
    "#            [Z,  Z,  I ]]\n",
    "# W2 = np.array(W2_list)\n",
    "\n",
    "# # W3: Shape (3, 3, 2, 2)\n",
    "# W3_list = [[I,  Z,  Z ],\n",
    "#            [Z,  sz, Z ],\n",
    "#            [Z,  Z,  sz]]\n",
    "# W3 = np.array(W3_list)\n",
    "\n",
    "# # W4: Shape (3, 1, 2, 2)\n",
    "# W4_list = [[I],\n",
    "#            [I],\n",
    "#            [sz]]\n",
    "# W4 = np.array(W4_list)\n",
    "\n",
    "# print(\" Basic operators and MPO tensors defined.\")\n",
    "# print(f\"Shape of W1: {W1.shape}\")\n",
    "# print(f\"Shape of W2: {W2.shape}\")\n",
    "# print(f\"Shape of W3: {W3.shape}\")\n",
    "# print(f\"Shape of W4: {W4.shape}\\n\")\n",
    "\n",
    "\n",
    "# # --- 3. Contract the MPO Chain ---\n",
    "# # We sequentially contract the tensors from left to right\n",
    "# print(\"Contracting MPO chain: W1 @ W2 @ W3 @ W4 ...\")\n",
    "# M_temp = contract_mpo_pair(W1, W2)\n",
    "# M_temp = contract_mpo_pair(M_temp, W3)\n",
    "# M_mpo_tensor = contract_mpo_pair(M_temp, W4)\n",
    "\n",
    "# # The final tensor has shape (1, 1, 16, 16). We squeeze it to get the 16x16 matrix.\n",
    "# M_mpo = M_mpo_tensor.squeeze()\n",
    "# print(\"Final MPO-derived matrix (first 4x4 block):\\n\", M_mpo[:4, :4].real)\n",
    "# print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# # --- 4. Construct the Exact Matrix for Verification ---\n",
    "# print(\"⚙️  Constructing exact matrix using Kronecker products for verification...\")\n",
    "# # M = sz*sz*I*I + I*sz*sz*I + I*I*sz*sz\n",
    "# M1 = np.kron(sz, np.kron(sz, np.kron(I, I)))\n",
    "# M2 = np.kron(I, np.kron(sz, np.kron(sz, I)))\n",
    "\n",
    "# M3 = np.kron(I, np.kron(I, np.kron(sz, sz)))\n",
    "# M_exact = M1 + M2 + M3\n",
    "\n",
    "# print(\"Final exact matrix (first 4x4 block):\\n\", M_exact[:4, :4].real)\n",
    "# print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# # --- 5. Compare the Results ---\n",
    "# # np.allclose checks if two arrays are element-wise equal within a tolerance.\n",
    "# are_matrices_equal = np.allclose(M_mpo, M_exact)\n",
    "\n",
    "# print(f\"Verification: Are the MPO and Exact matrices equal? \\n  {are_matrices_equal}\")\n",
    "\n",
    "# if are_matrices_equal:\n",
    "#     print(\"\\n Success! The MPO construction correctly reproduced the full operator.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
